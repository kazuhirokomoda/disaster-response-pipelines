# Disaster Response Pipelines

TODO: screenshots of web app and model results

## Project Motivation

- TODO: summary of the project

## Installation

### Dependencies

- TODO: Add dependencies

### How to run the project

1. Navigate yourself to the project's root directory.

2. To run ETL pipeline that cleans data and stores in database:

```
python data/process_data.py data/disaster_messages.csv data/disaster_categories.csv data/DisasterResponse.db
```

TODO: how to run the Python scripts and web app

## File Descriptions

TODO: improve as project advances

- `data/process_data.py` (ETL script, cleans data and stores in a SQLite database)
- `models/train_classifier.py` (ML script, trains a classifier and stores it into a pickle file)
- `app/run.py` (web app, includes visualizations using data from SQLite database)

## Licensing, Authors, Acknowledgements

TODO
